# -*- coding: utf-8 -*-
"""resnet50.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UbFnY66jxuXXXhtiIVIEN9adWcWTHYqz
"""

#%%
from __future__ import division

import numpy as np
import cv2
from keras import preprocessing
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras import optimizers
from sklearn.metrics import classification_report
from keras.applications.densenet import DenseNet121
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc

from keras.callbacks import ModelCheckpoint

BATCH_SIZE = 8
TARGET_SIZE = (224,224)
EPOCHS = 55
CODE = 'DENSE121'



def color_constancy(img):

    """
    Parameters
    ----------
    img: 2D numpy array
        The original image with format of (h, w, c)
    power: int
        The degree of norm, 6 is used in reference paper
    gamma: float
        The value of gamma correction, 2.2 is used in reference paper
    """
    img_dtype = img.dtype

    power = 6
    gamma = 2.2
    if gamma is not None:
        img = img.astype('uint8')
        look_up_table = np.ones((256,1), dtype='uint8') * 0
        for i in range(0,256):
            look_up_table[i][0] = 255*pow(i/255, 1/gamma)
        img = cv2.LUT(img, look_up_table)

    img = img.astype('float32')
    img_power = np.power(img, power)
    rgb_vec = np.power(np.mean(img_power, (0,1)), 1/power)
    rgb_norm = np.sqrt(np.sum(np.power(rgb_vec, 2.0)))
    rgb_vec = rgb_vec/rgb_norm
    rgb_vec = 1/(rgb_vec*np.sqrt(3))
    img = np.multiply(img, rgb_vec)
    
    return img.astype(img_dtype)
#%%
train_datagen = preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        rotation_range=60,
        shear_range = 0.2,
        zoom_range=0.2, 
        fill_mode='nearest', 
        preprocessing_function = color_constancy,
        dtype='float32')

test_datagen = preprocessing.image.ImageDataGenerator(
        preprocessing_function = color_constancy,
        rescale=1./255)

print("Train set: ")
train_generator = train_datagen.flow_from_directory(
        './train_crop',
        target_size= TARGET_SIZE,
        color_mode = 'rgb',
        batch_size=BATCH_SIZE,
        class_mode='categorical',
        seed = 42,
        shuffle = True
        )

print("val set: ")
val_generator = test_datagen.flow_from_directory(
        './val_crop',
        target_size=(TARGET_SIZE),
        color_mode='rgb',
        batch_size=BATCH_SIZE,
        class_mode="categorical",
        seed = 42,
        shuffle = False)

class_weights = { 0:3.0, 1:1.0, 2:3.0 }
print("class_weights: ", class_weights)

filepath = "./" + CODE + ".hdf5"
checkpoint = ModelCheckpoint(filepath, monitor = 'val_categorical_accuracy',\
                             verbose=1, save_best_only=True, save_weights_only=True, mode='max')
callbacks = [checkpoint]

#%%

base_model = DenseNet121(include_top=False, weights = 'imagenet', input_shape=(224, 224, 3), pooling = 'avg')
model = Sequential()    
model.add(base_model)
model.add(Dropout(0.2))
model.add(Dense(3, activation ="selu"))
model.add(Dense(3, activation ="selu"))
model.add(Dense(3,activation = 'softmax'))

#%%ath
#model.load_weights('./ISIC2017_' + CODE + '.h5')
    
adam = optimizers.Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999, amsgrad=False)
model.compile(optimizer=adam, loss='categorical_crossentropy',metrics = ['categorical_accuracy'])
                                                        
print(model.summary())
#%%
history = model.fit_generator(train_generator,
                              steps_per_epoch=None,
                              epochs=56,
                              class_weight=class_weights,
                              validation_data=val_generator,
                              callbacks = callbacks,
                              initial_epoch = 0
                              )

model.save_weights('./ISIC2017_' + CODE + '.h5')

#%%
probabilities = model.predict_generator(generator=val_generator)
y_true = val_generator.classes
y_pred = np.argmax(probabilities,axis = 1)

print(y_pred)

from sklearn import metrics

cm = metrics.confusion_matrix(y_true, y_pred)

print(cm)

import sklearn
sklearn.metrics.accuracy_score(y_true, y_pred)
print(y_true)
#%%
test_generator = test_datagen.flow_from_directory(
        './test_crop',
        target_size=(TARGET_SIZE),
        batch_size=BATCH_SIZE,
        class_mode="categorical",
        shuffle = False)

probabilities = model.predict_generator(generator=test_generator)
y_true = test_generator.classes
y_pred = np.argmax(probabilities,axis = 1)

print(y_pred)

from sklearn import metrics

cm = metrics.confusion_matrix(y_true, y_pred)
print(cm)

print ('------------------\n')

print(classification_report(y_true, y_pred))
#%%
model.load_weights('./ISIC2017_' + CODE + '.h5')
#%%
for layer in base_model.layers:
    layer.trainable = False
#%%

def cycle(iterable):
    # cycle('ABCD') --> A B C D A B C D A B C D ...
    saved = []
    for element in iterable:
        yield element
        saved.append(element)
    while saved:
        for element in saved:
              yield element
# Binarize the output
y = label_binarize(y_true, classes=[0, 1, 2])
n_classes = y.shape[1]


fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y[:, i], prob[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

colors = cycle(['blue', 'red', 'green'])
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label='ROC curve of class {0} (area = {1:0.3f})'
             ''.format(i, roc_auc[i]))
plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([-0.05, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic for multi-class data')
plt.legend(loc="lower right")
plt.show()

